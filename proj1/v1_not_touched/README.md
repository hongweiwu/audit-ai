# 项目说明

运用机器学习判断采购过程中是否存在舞弊行为、及舞弊的类别


## 文件结构

- `data/`：逗号分隔（`.csv`）格式的数据文件，包含正向与反向；
- `model/`：经过训练的机器学习模型以HDF5二进制格式（`.h5`）存放在该目录下；
- `mlp.py` \& `predict.py`：机器学习算法和预测模型的主程序文件；
- `demo.ipynb`：机器学习成果的测试和演示。


## 程序使用说明

#### 准备工作

在使用程序之前，请确保以下内容：

- 数据文件以csv的格式存放在`data/`文件夹下，文件名与程序中对应，且全部使用utf-8编码；
- 系统环境配置完成，具体可在bash中使用如下命令（`$`符号之后的），逐一执行。
```
$ source activate tf
(tf) $ cd ~/sf/sf-project/
(tf) $ git pull
```

#### 程序功能

此机器学习程序包含以下2个模型：

- 判断一笔订单是否存在舞弊的二分模型（以下简称“判断模型”）；
- 基于一笔订单存在舞弊的事实，给其中的违规行为分类的模型（以下简称“分类模型”）。

具体而言，基于我们编写的多个程序文件，可实现如下功能（以及相应的实现方法）：

- 训练判断模型，并在现有的数据集上进行10-fold cross validation，计算平均的预测准确率；
```
(tf) $ python mlp.py --binary --epochs=20
```


- 训练分类模型，并进行cross validation，计算平均的预测准确率；
```
(tf) $ python mlp.py --multiclass --epochs=20
```


- 训练判断模型，使用数据集中的所有数据，并将成果保存在`model/binary.h5`文件中；
```
(tf) $ python mlp.py --binary --epochs=20 --save
```


- 训练分类模型，并将成果保存在`model/multi.h5`文件中；
```
(tf) $ python mlp.py --multiclass --epochs=20 --save
```


- 针对一批尚待判断的数据，甄别出最有舞弊嫌疑的50条订单，并尝试给出它们各自的违规类别。
```
(tf) $ python predict.py
```


#### Notebook演示

文件`demo.ipynb`是一个jupyter notebook写成的对机器学习过程的演示。它包含训练过程的展示，以及一个简单的判断准确度测试。请按如下步骤来使用：

1. 启动jupyter notebook：输入如下命令后，保持bash窗口打开；
```
(tf) $ jupyter notebook
```
2. 浏览器会自动跳转到notebook的首页；若没有跳转，请在地址栏输入`localhost:8888`，然后搜寻第1步中`?token=`字段，输入token解锁网页；
3. 点击`demo.ipynb`跳转到演示使用的notebook页面；
4. 依次对每一个含有代码的cell选中，然后按`ctrl-enter`快捷键执行，可以看到代码运行的过程；
5. 最后的几个窗口中，就包含测试使用的判断样例，以及对判断结果的汇总；
6. 要停止notebook服务，回到第1步中的窗口，然后按`ctrl-c`，输入确认y后来停止。


#### 增加因子的注意点

后续增加训练因子的过程中，模型本身无需调整，但需要调整`mlp.py`中`load_data_*()`的几个函数；需要注意的如下：

- 机器学习模型的输入数据是`numpy`的2d array，因此建议新函数代码的撰写者熟悉`numpy`库的使用；
- 对新数据中的因子，要确保输入机器时不含`string`类型的数据，可以调用`np.delete`来删除含有字串的列；
- 为了配合数据的标准化，每增加一个因子，请将这一列的最小值填入`mlp.py`开头的`minval`数组中，将最大值与最小值的差填入`denom`数组中，详见附注；
- 如果处理后返回的array不符合要求，代码会在训练之前报错，请根据错误信息相应调整。


## 时间线

- 2017年5月21日：创建Github repository，并上传基本的项目文件。
- 6月11日：数据因子梳理工作全部完成。    
- 6月21日：初步机器学习模型构建完成，等待数据请求发还、进行训练。
- 6月22日：完成双向案例分析，得到不完整的可用于学习数据库，完成第一阶段训练与优化。
- 6月23日：在6月22日学习基础上进行了第二阶段模型优化，改进了机器学习有效性的检测方式以及部分算法。
    - 同日，得到2017年的全新数据并得出机器检测结果，首次将全新数据应用在模型上。


## 项目开发者

- 白金（邮箱[jinbai2@illinois.edu](mailto:jinbai2@illinois.edu)）
- 裘通（邮箱[tonyqiu1019@gmail.com](mailto:tonyqiu1019@gmail.com)）


## 鸣谢

感谢上海财经大学会计学院的饶艳超教授，和Arbutus软件公司的林志军先生对项目的大力支持。


## 附注

#### 注1：关于数据标准化

主程序中，全部使用`(value - min) / (max - min)`的方法进行标准化，因此需要将`minval`和`denom`数组保存在文件开头。这种线性标准化的方法对数据做了一定预设，因此也许不是最佳方案。事实上，最佳的标准化方案有待商榷，也是这个课题未来发展中亟待解决的一个问题。


#### 注2：关于机器学习库的选择

本模型采用基于[Tensorflow](https://www.tensorflow.org)的[Keras](https://keras.io)作为机器学习代码库，具有以下优势：

- Keras作为神经网络领域备受欢迎的代码库，使用方法非常简洁，可以达到以最少的代码量搭建模型；
- Keras支持以神经元层级的形式构建神经网络模型，代码清晰易懂，并且在评估学习结果时模型易于调整；
- 以Tensorflow作为backend支持，充分利用到了GPU的高速浮点运算能力，并且兼容性良好。
