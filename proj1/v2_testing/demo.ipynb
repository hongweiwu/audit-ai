{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Demo\n",
    "\n",
    "This file demonstrates the process of training the model, and invoking the saved model under the `model/` directory to make inferences.\n",
    "\n",
    "First we need to import the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import csv\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different categories of violations should be given different indices, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "violation = {\n",
    "    '采购策略问题': 0,\n",
    "    '串标':1,\n",
    "    '虚假业务':2,\n",
    "    '收受回扣':3,\n",
    "    '流程违规':4,\n",
    "    '成本偏高':5,\n",
    "}\n",
    "\n",
    "minval = [1.0, 0, 3401001, -100000000, 101, 1000, -100000000]\n",
    "denom = [1000052162559.0, 88717952, 1100000, 200000000, 300, 2780, 200000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a useful method to read csv data as `numpy` arrays, so we define it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, mode='binary'):\n",
    "    # open the file and read contents as a list\n",
    "    r = csv.reader(open(fname, 'r'), delimiter=',', quotechar='\"')\n",
    "    raw_data = np.array(list(r))\n",
    "    \n",
    "    # process the given data and convert it to floats\n",
    "    str_data = np.delete(raw_data[1:, 1:], [7], axis=1)\n",
    "    if mode == 'binary':\n",
    "        for i in range(str_data.shape[0]):\n",
    "            str_data[i,5] = 0 if str_data[i,5] == 'normal' else 1\n",
    "    else:\n",
    "        for i in range(str_data.shape[0]):\n",
    "            str_data[i,5] = violation[str_data[i,5].split('；')[0]]\n",
    "    \n",
    "    data = str_data.astype('float32')\n",
    "    \n",
    "    # y_data is the ground truth\n",
    "    y_data = data[:, 5]\n",
    "    data = np.delete(data, [5], axis=1)\n",
    "    \n",
    "    # x_data is the vector to feed the model\n",
    "    x_data = np.empty(data.shape)\n",
    "    \n",
    "    # normalize all data\n",
    "    for i in range(data.shape[1]):\n",
    "        min_arr = np.full((data.shape[0],), minval[i])\n",
    "        x_data[:,i] = (data[:,i] - min_arr) / denom[i]\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Check that there is no existing model in the directory now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -f model/*; ls model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the binary classifier for 20 epochs, and make it save the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 267,778.0\n",
      "Trainable params: 267,778.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2017-06-23 15:48:17.376110: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:17.376143: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:17.376148: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:17.376163: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:17.376167: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:17.487472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-06-23 15:48:17.487813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti\n",
      "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
      "pciBusID 0000:01:00.0\n",
      "Total memory: 10.91GiB\n",
      "Free memory: 10.53GiB\n",
      "2017-06-23 15:48:17.487824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n",
      "2017-06-23 15:48:17.487827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n",
      "2017-06-23 15:48:17.487831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)\n",
      "49920/49920 [==============================] - 1s - loss: 0.5139 - acc: 0.7378     \n",
      "Epoch 2/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.4518 - acc: 0.7853     \n",
      "Epoch 3/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.4279 - acc: 0.7974     \n",
      "Epoch 4/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.4125 - acc: 0.8065     \n",
      "Epoch 5/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.4037 - acc: 0.8093     \n",
      "Epoch 6/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3967 - acc: 0.8136     \n",
      "Epoch 7/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3902 - acc: 0.8202     \n",
      "Epoch 8/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3846 - acc: 0.8232     \n",
      "Epoch 9/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3792 - acc: 0.8264     \n",
      "Epoch 10/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3718 - acc: 0.8320     \n",
      "Epoch 11/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3704 - acc: 0.8336     \n",
      "Epoch 12/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3622 - acc: 0.8403     \n",
      "Epoch 13/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3569 - acc: 0.8419     \n",
      "Epoch 14/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3542 - acc: 0.8435     \n",
      "Epoch 15/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3492 - acc: 0.8478     \n",
      "Epoch 16/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3457 - acc: 0.8467     \n",
      "Epoch 17/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3477 - acc: 0.8479     \n",
      "Epoch 18/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3421 - acc: 0.8509     \n",
      "Epoch 19/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3336 - acc: 0.8560     \n",
      "Epoch 20/20\n",
      "49920/49920 [==============================] - 0s - loss: 0.3277 - acc: 0.8592     \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "successfully saved the model at model/binary.h5\n"
     ]
    }
   ],
   "source": [
    "!python mlp.py --binary --save --epochs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Now load the saved binary file of the model, namely `model/binary.h5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_b = load_model('model/binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the testing csv data, namely `data/test_b.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_b, y_data_b = read_data('data/test_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 10 random columns denoted by `col`, and make inference using the loaded model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = range(100)  # can change indices\n",
    "y_predict_b = np.argmax(model_b.predict(x_data_b[col]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results almost (or exactly) match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferenced:\t [0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1]\n",
      "Ground truth:\t [0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Inferenced:\\t', y_predict_b)\n",
    "print('Ground truth:\\t', y_data_b[col].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(y_predict_b.shape[0]):\n",
    "    correct += 1 if y_predict_b[i] == y_data_b[col][i] else 0\n",
    "\n",
    "print('accuracy:', correct/y_predict_b.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass\n",
    "\n",
    "The multiclass classifier distinguishes between different kinds of frauds. The training and inference process is similar; below is the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 269,830.0\n",
      "Trainable params: 269,830.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2017-06-23 15:48:32.751403: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:32.751420: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:32.751424: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:32.751427: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:32.751429: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-23 15:48:32.824122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-06-23 15:48:32.824295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti\n",
      "major: 6 minor: 1 memoryClockRate (GHz) 1.582\n",
      "pciBusID 0000:01:00.0\n",
      "Total memory: 10.91GiB\n",
      "Free memory: 321.38MiB\n",
      "2017-06-23 15:48:32.824306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n",
      "2017-06-23 15:48:32.824310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n",
      "2017-06-23 15:48:32.824315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)\n",
      "24320/24320 [==============================] - 0s - loss: 0.2178 - acc: 0.9444     \n",
      "Epoch 2/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1294 - acc: 0.9752     \n",
      "Epoch 3/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1221 - acc: 0.9757     \n",
      "Epoch 4/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1191 - acc: 0.9761     \n",
      "Epoch 5/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1160 - acc: 0.9760     \n",
      "Epoch 6/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1160 - acc: 0.9762     \n",
      "Epoch 7/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1149 - acc: 0.9760     \n",
      "Epoch 8/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1154 - acc: 0.9761     \n",
      "Epoch 9/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1141 - acc: 0.9759     \n",
      "Epoch 10/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1138 - acc: 0.9759     \n",
      "Epoch 11/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1120 - acc: 0.9760     \n",
      "Epoch 12/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1110 - acc: 0.9762     \n",
      "Epoch 13/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1077 - acc: 0.9760     \n",
      "Epoch 14/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1057 - acc: 0.9760     \n",
      "Epoch 15/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.1015 - acc: 0.9762     \n",
      "Epoch 16/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.0971 - acc: 0.9769     \n",
      "Epoch 17/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.0939 - acc: 0.9762     \n",
      "Epoch 18/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.0888 - acc: 0.9776     \n",
      "Epoch 19/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.0863 - acc: 0.9783     \n",
      "Epoch 20/20\n",
      "24320/24320 [==============================] - 0s - loss: 0.0795 - acc: 0.9796     \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "successfully saved the model at model/multi.h5\n"
     ]
    }
   ],
   "source": [
    "!python mlp.py --multiclass --save --epochs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below is the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_m = load_model('model/multi.h5')\n",
    "x_data_m, y_data_m = read_data('data/test_m.csv', mode='multi')\n",
    "\n",
    "col = range(100)  # can change indices\n",
    "y_predict_m = np.argmax(model_m.predict(x_data_m[col]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the results almost (or exactly) match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferenced:\t [3 1 3 0 3 3 3 1 3 3 0 3 1 1 0 3 0 1 1 1 1 3 3 1 0 0 3 1 1 3 1 3 1 0 1 1 1\n",
      " 1 0 1 3 1 1 0 0 0 0 1 1 1 1 1 3 0 1 0 3 1 1 3 3 0 1 1 1 1 1 3 1 0 1 1 0 3\n",
      " 1 0 1 1 1 1 1 1 3 0 1 1 1 0 3 1 1 3 0 3 1 1 3 3 1 1]\n",
      "Ground truth:\t [3 1 3 0 3 3 3 1 3 3 0 3 1 1 3 3 0 1 1 1 1 3 3 1 0 0 3 1 1 3 1 3 1 0 1 1 1\n",
      " 1 0 1 3 1 1 0 0 0 0 1 1 1 1 1 3 0 1 0 3 1 1 3 3 0 1 1 1 1 1 3 1 0 1 1 0 3\n",
      " 1 0 1 1 1 1 1 1 3 0 1 1 1 0 3 1 1 3 0 3 1 1 3 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Inferenced:\\t', y_predict_m)\n",
    "print('Ground truth:\\t', y_data_m[col].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(y_predict_m.shape[0]):\n",
    "    correct += 1 if y_predict_m[i] == y_data_m[col][i] else 0\n",
    "\n",
    "print('accuracy:', correct/y_predict_m.shape[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
